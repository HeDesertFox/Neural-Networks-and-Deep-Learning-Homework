{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自监督学习\n",
    "框架：MoCo\n",
    "数据集：mini-Imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heyh0\\.conda\\envs\\deeplearning39\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\heyh0\\.conda\\envs\\deeplearning39\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\heyh0\\.conda\\envs\\deeplearning39\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from data_preparation import get_dataloaders\n",
    "from model import get_resnet18_model, add_fc_layer\n",
    "from pretraining import MoCo, train_moco\n",
    "from training_finetuning import train_and_validate, finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "batch_size = 128\n",
    "num_epochs_pretrain = 200\n",
    "num_epochs_finetune = 10   #应该是100\n",
    "num_classes = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造 Data Loader（如果使用tiny-imagenet数据集会比较慢）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 获取数据加载器\n",
    "dataset_type = 'mini'  # 可以选择 'tiny' 或 'mini'\n",
    "imagenet_loader, train_loader_cifar100, test_loader_cifar100 = get_dataloaders(batch_size, data_type=dataset_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 保存数据集对象\n",
    "# torch.save(imagenet_loader.dataset, 'imagenet_loader.pth')\n",
    "# torch.save(train_loader_cifar100.dataset, 'train_loader_cifar100.pth')\n",
    "# torch.save(test_loader_cifar100.dataset, 'test_loader_cifar100.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接导入data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 重新加载数据集对象的示例代码（注释掉，仅供参考）\n",
    "# imagenet_dataset = torch.load('imagenet_loader.pth')\n",
    "# train_dataset_cifar100 = torch.load('train_loader_cifar100.pth')\n",
    "# test_dataset_cifar100 = torch.load('test_loader_cifar100.pth')\n",
    "# imagenet_loader = DataLoader(imagenet_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# train_loader_cifar100 = DataLoader(train_dataset_cifar100, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# test_loader_cifar100 = DataLoader(test_dataset_cifar100, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoCo 预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 这段代码用来测试MoCo的训练是否正常，用最小的数据集测试会快一些\n",
    "# imagenet_loader = test_loader_cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MoCo pre-training on mini-ImageNet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heyh0\\.conda\\envs\\deeplearning39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\heyh0\\.conda\\envs\\deeplearning39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# MoCo 预训练\n",
    "print(f\"Starting MoCo pre-training on {dataset_type}-ImageNet...\")\n",
    "moco_model = MoCo(base_encoder=get_resnet18_model, dim=128, K=65536, m=0.999, T=0.07, mlp=False).cuda()\n",
    "moco_optimizer = optim.Adam(moco_model.parameters(), lr=3e-3, weight_decay=1e-4)\n",
    "moco_criterion = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moco_writer = SummaryWriter(log_dir='logs/moco')\n",
    "\n",
    "for epoch in range(num_epochs_pretrain):\n",
    "    train_loss = train_moco(imagenet_loader, moco_model, moco_criterion, moco_optimizer, epoch, moco_writer)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_pretrain}], MoCo Loss: {train_loss:.4f}')\n",
    "moco_writer.close()\n",
    "\n",
    "# 保存 MoCo 预训练模型权重\n",
    "torch.save(moco_model.state_dict(), 'moco_pretrained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新导入模型权重的语句\n",
    "# moco_model.load_state_dict(torch.load('moco_pretrained.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 微调\n",
    "只在MoCo预训练模型上微调。此参数将同时用于三个模型\n",
    "\n",
    "本实验只微调学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 MoCo 预训练的 encoder_q\n",
    "moco_pretrained_model = moco_model.encoder_q\n",
    "moco_pretrained_model.model.fc = nn.Identity()  # 确保最后一层是恒等映射\n",
    "full_moco_pretrained_model = add_fc_layer(moco_pretrained_model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [1e-3, 3e1]  #注意一下不寻常的学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 微调和评估 MoCo 预训练模型\n",
    "print(\"Finetuning MoCo pre-trained model on CIFAR-100...\")\n",
    "best_lr = finetune(train_loader_cifar100, test_loader_cifar100, full_moco_pretrained_model, learning_rate_list, num_epochs_finetune)\n",
    "print(f'Best learning rate for fine-tuning: {best_lr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重新训练模型，可视化训练曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练自监督模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估 MoCo 预训练模型\n",
    "print(\"Evaluating MoCo pre-trained model on CIFAR-100...\")\n",
    "moco_pretrained_model = moco_model.encoder_q\n",
    "moco_pretrained_model.model.fc = nn.Identity()  # 确保最后一层是恒等映射\n",
    "full_moco_pretrained_model = add_fc_layer(moco_pretrained_model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以在这里直接设置学习率\n",
    "best_lr = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最佳学习率训练和评估 MoCo 预训练模型\n",
    "print(\"Training MoCo pre-trained model on CIFAR-100 with best learning rate...\")\n",
    "finetune_optimizer = optim.Adam([\n",
    "    {'params': full_moco_pretrained_model[:-1].parameters(), 'lr': best_lr / 10},\n",
    "    {'params': full_moco_pretrained_model[-1].parameters(), 'lr': best_lr}\n",
    "])\n",
    "finetune_writer = SummaryWriter(log_dir='logs/moco_finetune')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs_finetune):\n",
    "    train_loss, train_acc, val_loss, val_acc = train_and_validate(train_loader_cifar100, test_loader_cifar100, full_moco_pretrained_model, criterion, finetune_optimizer, epoch, finetune_writer)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_finetune}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "finetune_writer.close()\n",
    "\n",
    "# 保存 MoCo 预训练并微调后的模型权重\n",
    "torch.save(full_moco_pretrained_model.state_dict(), 'moco_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新导入模型权重的语句\n",
    "# full_moco_pretrained_model.load_state_dict(torch.load('moco_finetuned.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练监督模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估 ImageNet 预训练模型\n",
    "print(\"Evaluating ImageNet pre-trained model on CIFAR-100...\")\n",
    "imagenet_pretrained_model = get_resnet18_model(pretrained=True).cuda()\n",
    "full_imagenet_pretrained_model = add_fc_layer(imagenet_pretrained_model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以在这里直接设置学习率\n",
    "imagenet_best_lr = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最佳学习率训练和评估 ImageNet 预训练模型\n",
    "print(\"Training ImageNet pre-trained model on CIFAR-100 with best learning rate...\")\n",
    "finetune_optimizer = optim.Adam([\n",
    "    {'params': full_imagenet_pretrained_model[:-1].parameters(), 'lr': imagenet_best_lr / 10},\n",
    "    {'params': full_imagenet_pretrained_model[-1].parameters(), 'lr': imagenet_best_lr}\n",
    "])\n",
    "imagenet_finetune_writer = SummaryWriter(log_dir='logs/imagenet_finetune')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs_finetune):\n",
    "    train_loss, train_acc, val_loss, val_acc = train_and_validate(train_loader_cifar100, test_loader_cifar100, full_imagenet_pretrained_model, criterion, finetune_optimizer, epoch, imagenet_finetune_writer)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_finetune}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "imagenet_finetune_writer.close()\n",
    "\n",
    "# 保存 ImageNet 预训练并微调后的模型权重\n",
    "torch.save(full_imagenet_pretrained_model.state_dict(), 'imagenet_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新导入模型权重的语句\n",
    "# full_imagenet_pretrained_model.load_state_dict(torch.load('imagenet_finetuned.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练随机初始化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练和评估随机初始化模型\n",
    "print(\"Training randomly initialized model on CIFAR-100...\")\n",
    "random_init_model = get_resnet18_model(pretrained=False).cuda()\n",
    "full_random_init_model = add_fc_layer(random_init_model, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可以在这里直接设置学习率\n",
    "random_best_lr = 2e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最佳学习率训练和评估随机初始化模型\n",
    "print(\"Training randomly initialized model on CIFAR-100 with best learning rate...\")\n",
    "finetune_optimizer = optim.Adam([\n",
    "    {'params': full_random_init_model.parameters(), 'lr': random_best_lr}\n",
    "])\n",
    "random_finetune_writer = SummaryWriter(log_dir='logs/random_finetune')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs_finetune):\n",
    "    train_loss, train_acc, val_loss, val_acc = train_and_validate(train_loader_cifar100, test_loader_cifar100, full_random_init_model, criterion, finetune_optimizer, epoch, random_finetune_writer)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs_finetune}], Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "random_finetune_writer.close()\n",
    "\n",
    "# 保存随机初始化并微调后的模型权重\n",
    "torch.save(full_random_init_model.state_dict(), 'random_finetuned.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新导入模型权重的语句\n",
    "# full_random_init_model.load_state_dict(torch.load('random_finetuned.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
